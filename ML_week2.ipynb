{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3796e04",
   "metadata": {},
   "source": [
    "## 컴퓨터 인식이란?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c796d7",
   "metadata": {},
   "source": [
    "인공지능 : 패턴 인식, 머신 러닝 딥러닝\n",
    "\n",
    "패턴 인식 : 이미지를 특정 사물로 자동 인식하는 작업\n",
    "\n",
    "머신 러닝 : 90년대 확률과 통계등 다양한 방법을 동원한 머신 러닝 기술들이 개발되었다.\n",
    "\n",
    "딥러닝 : 뇌의 뉴런 구조를 통해, 인공지능 기술을 구현하는 기술"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb32710",
   "metadata": {},
   "source": [
    "## 어떻게 패턴을 인식하는가?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508cec39",
   "metadata": {},
   "source": [
    "어떻게 패턴을 인식할 수 있을까?\n",
    "\n",
    "원천 소스 : 원본 데이터 (raw data)\n",
    "\n",
    "패턴 (전처리 데이터) : 분류기에 입력 가능하도록 전처리한 데이터\n",
    "\n",
    "부류 (class) : 학습된 인식 결과 종류\n",
    "\n",
    "분류 (calssification) : 기존 학습된 부류(class)에 가깝다고 판단하는 것"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b9f8aa",
   "metadata": {},
   "source": [
    "## 어떻게 분류할 수 있을까?\n",
    "- 학습을 통해, 분류기를 만듬"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8568c7cc",
   "metadata": {},
   "source": [
    "1. 샘플 : 수집된 다양한 데이터 ( 전체 데이터가 아님, 원본 데이터를 전처리한 데이터)\n",
    "\n",
    "2. 샘플을 두 집합으로 분리\n",
    "\n",
    "- training set : 정답까지 기재된 샘플들\n",
    "- test set : 정답은 기재되지 않은 샘플들\n",
    "\n",
    "3. 분류기 설계 : 분류할 모델 선정\n",
    "\n",
    "4. 분류할 모델에 맞도록 샘플에서 featuer 추출 또는 가공 / feature engineering\n",
    "\n",
    "5. 훈련 집합을 분류기에 넣어, 학습\n",
    "\n",
    "6. 테스트 집합으로 부누류기 성능 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcabab2c",
   "metadata": {},
   "source": [
    "## 현실세계 데이터라면 샘플을 어떻게 컴퓨터에게 전달할까?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff83e10",
   "metadata": {},
   "source": [
    "- 데이터를 컴퓨터가 이해할 수 있도록 바꾼다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a75d455",
   "metadata": {},
   "source": [
    "수학, 확률/통계 등 다양한 기법을 사용하여 분류를 진행한다. (다양한 모델을 선택 사용)\n",
    "\n",
    "성능평가 : 분류 목적에 맞게, 정의한 수학식을 통해, 분류 성능을 평가\n",
    "\n",
    "단순히 맞다/아니다 외에 분류 목적에 맞게 다양한 성능 평가식이 있을 수 있음\n",
    "\n",
    "Precision (정확도) : 실제 1 / 예측 1 = TP / TP + FP\n",
    "\n",
    "Recall (재현율) : TP / TP + FN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec86ab0",
   "metadata": {},
   "source": [
    "1. 데이터를 수집하고 - Crawling, SQL/NoSQL\n",
    "\n",
    "2. 데이터를 전처리하고 (보통 숫자) - pandas\n",
    "\n",
    "3. 특징을 가공 / 추출\n",
    "\n",
    "4. 모델을 정의, 훈련 집합으로 모델을 학습시킨다 - scikit-learn과 같은 라이브러리\n",
    "\n",
    "5. 테스트 집합으로 학습된 모델을 테스트하고, 정의한 성능 평가식으로 평가한다. - scikit-learn과 같은 라이브러리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da82dafa",
   "metadata": {},
   "source": [
    "## 대부분의 모델은 결국 수학\n",
    "- 컴퓨터는 수학을 매우 잘함\n",
    "- 데이터를 숫자로 바꾸고, 최적화를 위한 수학 공식을 코드로 만들어 컴퓨터가 계산하게 만듬"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf27aaa",
   "metadata": {},
   "source": [
    "- 확률과 통계\n",
    "- 선형 대수\n",
    "- 정보 이론\n",
    "- 최적화\n",
    "- 미분"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7144e3c",
   "metadata": {},
   "source": [
    "## 사람의 인식을 생각해본다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07900db",
   "metadata": {},
   "source": [
    "- 보편적인 인식 법칙\n",
    "- 가장 그럴듯한 부류(class)로 분류한다\n",
    "\n",
    "확률로 각 부류에 그럴듯한지를 계산하여 판단한다.\n",
    "ex) P(X|Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7f2ab1",
   "metadata": {},
   "source": [
    "## 확률 기초"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7269f8",
   "metadata": {},
   "source": [
    "랜덤 변수 : 확률로 결정되는 결과값\n",
    "\n",
    "결합 확률 = Multiply\n",
    "\n",
    "주변 확률 = Sum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b1abd8",
   "metadata": {},
   "source": [
    "## 독립 (independent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9fc38d",
   "metadata": {},
   "source": [
    "- 두 랜덤 변수가 독립이려면 P(X,Y) = P(X)P(Y)이어야 한다. -> 베이즈 정리의 기본이 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ac40fc",
   "metadata": {},
   "source": [
    "## 사전확률 (Prior probability)\n",
    "- 두번째 사건이 발생하기 전의 사건 발생 확률"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be853d90",
   "metadata": {},
   "source": [
    "## 우도함수와, 사후 확률\n",
    "- 우도는 조건부 확률로 계산 가능\n",
    "- 우도 함수 (likelihood)\n",
    "- 사후 확률은 기본적으로는 계산 불가 -> 결과가 발생하였다는 조건 하에 이 결과가 원인으로 인해 발생하였을 확률\n",
    "\n",
    " ** 우리가 구하고 싶은 확률은 사후 확률이다.\n",
    " \n",
    "ex) \n",
    "1. P(A|딸기맛) - 사후확률\n",
    "2. P(딸기맛|A) - 우도\n",
    "3. P(A) - 사전 확률\n",
    "\n",
    "- 원칙적으로는 사후 확률을 구할 수 없다! 하지만 Bayes' theorem에 의하면 사후 확률은 사전 확률과 우도를 사용하여 계산할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6c1485",
   "metadata": {},
   "source": [
    "## 베이즈 정리(Bayes rule)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2c46b1",
   "metadata": {},
   "source": [
    "다음 두 결합 확률은 같다라는 공식에서 출발 (결합 확률 곱셈 법칙)\n",
    "\n",
    "P(X|Y) = P(Y|X)\n",
    "\n",
    "조건부 확률로 풀어서 써보기\n",
    "\n",
    "P(X|Y) = P(X) x P(Y|X)\n",
    "\n",
    "P(Y|X) = P(Y) x P(X|Y) : 사후 확률\n",
    "\n",
    "P(X) x P(Y|X) = P(Y) x P(X|Y)\n",
    "\n",
    "- P(X|Y) = P(X) x P(Y|X) / P(Y)\n",
    "\n",
    "- P(Y) = 주변확률 = P(딸기맛)\n",
    "\n",
    "사후 확률 = 우도 X 사전확률 / 주변확률\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41502ff2",
   "metadata": {},
   "source": [
    "## 베이즈 문제 풀이는 IN 테블릿..\n",
    "\n",
    "- 딸기맛 사탕 선택\n",
    "- 스팸 메일 분류하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5b7f2c",
   "metadata": {},
   "source": [
    "## 필기체 인식을 위한 베이시언 분류기\n",
    "- 베이지언 분류기 : 주어진 특징 벡터 X에 대해 '가장 그럴듯한' 부류로 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef29f56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
